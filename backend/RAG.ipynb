{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71d5e05",
   "metadata": {},
   "source": [
    "#### Setup and Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fd842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install -q google-generativeai python-dotenv langchain faiss-cpu langchain_google_genai langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487816b",
   "metadata": {},
   "source": [
    "#### 1. Importing libraries and setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11dbe5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pruthvi-s/Desktop/Portfolio_Website_With_Chatbot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bfd1a",
   "metadata": {},
   "source": [
    "#### Load environment variables (make sure you have a .env file with GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b3d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705542a",
   "metadata": {},
   "source": [
    "#### 3. Functions for chunking and creating the vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad9fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the text data\n",
    "def get_text_from_file(txt_file):\n",
    "    \"\"\"\n",
    "    Extracts text from a single text file.\n",
    "    \n",
    "    Args:\n",
    "        txt_file (str): The file path to the text document.\n",
    "    \n",
    "    Returns:\n",
    "        str: The content of the text file.\n",
    "    \"\"\"\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "#Function to create the chunks from the text data\n",
    "def get_chunks(text):\n",
    "    \"\"\"\n",
    "    Splits a long string of text into smaller chunks.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to be chunked.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of text chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=250)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "#Function to create a vector store from the text chunks\n",
    "def get_vector_store(text_chunks):\n",
    "    \"\"\"\n",
    "    Creates a FAISS vector store from text chunks and saves it locally.\n",
    "    \n",
    "    Args:\n",
    "        text_chunks (list): A list of text chunks.\n",
    "    \"\"\"\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "    print(\"Vector store created and saved as 'faiss_index'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef61c5",
   "metadata": {},
   "source": [
    "#### 4.Main execution in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b21d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and saved as 'faiss_index'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt_file_path = \"data.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(txt_file_path):\n",
    "    print(f\"Error: The file '{txt_file_path}' was not found. Please create it and add your text content.\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. Read the text from the file\n",
    "        raw_text = get_text_from_file(txt_file_path)\n",
    "        \n",
    "        # 2. Get the text chunks\n",
    "        text_chunks = get_chunks(raw_text)\n",
    "\n",
    "        # 3. Create and save the vector store\n",
    "        get_vector_store(text_chunks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
